{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698fdb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events: 100\n",
      "Table 1:\n",
      "\n",
      "╒════════════════════╤═══════════════════╤════════════════════╕\n",
      "│ True / Predicted   │   Predicted Noise │   Predicted Signal │\n",
      "╞════════════════════╪═══════════════════╪════════════════════╡\n",
      "│ True Noise         │        0.634675   │          0.0116786 │\n",
      "├────────────────────┼───────────────────┼────────────────────┤\n",
      "│ True Signal        │        0.00209525 │          0.351551  │\n",
      "╘════════════════════╧═══════════════════╧════════════════════╛\n",
      "Table 2:\n",
      "\n",
      "╒═════════════════════╤═══════════════════╕\n",
      "│ Matched/Unmatched   │   Energy Fraction │\n",
      "╞═════════════════════╪═══════════════════╡\n",
      "│ Matched Truth       │        0.991712   │\n",
      "├─────────────────────┼───────────────────┤\n",
      "│ Unmatched Truth     │        0.00828761 │\n",
      "├─────────────────────┼───────────────────┤\n",
      "│ Matched Predicted   │        0.935539   │\n",
      "├─────────────────────┼───────────────────┤\n",
      "│ Unmatched Predicted │        0.0644611  │\n",
      "╘═════════════════════╧═══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load set number of .pkl files\n",
    "file_pattern = r'C:\\Users\\tsoli\\OneDrive\\Documents\\School\\1 - University of Minnesota\\Year 17\\Year 1 Research\\picklefiles\\tau\\*.pkl'\n",
    "file_limit = 100\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        score_noise_filter = pickle.load(f)\n",
    "        pass_noise_filter = pickle.load(f)\n",
    "        out_gravnet = pickle.load(f)\n",
    "    return data, score_noise_filter, pass_noise_filter, out_gravnet\n",
    "\n",
    "def get_clustering(beta: np.array, X: np.array, threshold_beta: float = .2, threshold_dist: float = 0.5) -> np.array:\n",
    "    n_points = beta.shape[0]\n",
    "    select_condpoints = beta > threshold_beta\n",
    "    indices_condpoints = np.nonzero(select_condpoints)[0]\n",
    "    indices_condpoints = indices_condpoints[np.argsort(-beta[select_condpoints])]\n",
    "    unassigned = np.arange(n_points)\n",
    "    clustering = -1 * np.ones(n_points, dtype=np.int32)\n",
    "    \n",
    "    for index_condpoint in indices_condpoints:\n",
    "        d = np.linalg.norm(X[unassigned] - X[index_condpoint], axis=-1)\n",
    "        assigned_to_this_condpoint = unassigned[d < threshold_dist]\n",
    "        clustering[assigned_to_this_condpoint] = index_condpoint\n",
    "        unassigned = unassigned[~(d < threshold_dist)]\n",
    "    \n",
    "    return clustering\n",
    "\n",
    "def process_data(data):\n",
    "    true_energies = data.x[:, 0].numpy()\n",
    "    true_clusters = data.y.numpy()\n",
    "    return true_energies, true_clusters\n",
    "\n",
    "def process_gravnet(score_noise_filter, pass_noise_filter, out_gravnet):\n",
    "    beta = torch.sigmoid(out_gravnet[:, 0]).numpy()\n",
    "    cluster_space_coords = out_gravnet[:, 1:].numpy()\n",
    "    pred_clusters_pnf = get_clustering(beta, cluster_space_coords, threshold_beta=0.2, threshold_dist=0.5)\n",
    "    pred_clusters = np.zeros_like(pass_noise_filter, dtype=np.int32)\n",
    "    pred_clusters[pass_noise_filter] = pred_clusters_pnf\n",
    "    return pred_clusters\n",
    "\n",
    "def compute_statistics(true_energies, true_clusters, pred_clusters):\n",
    "    total_energy = np.sum(true_energies)\n",
    "    true_signal_energy = np.sum(true_energies[true_clusters != 0])\n",
    "    true_noise_energy = np.sum(true_energies[true_clusters == 0])\n",
    "    pred_signal_energy = np.sum(true_energies[pred_clusters != 0])\n",
    "    pred_noise_energy = np.sum(true_energies[pred_clusters == 0])\n",
    "    \n",
    "    correct_noise = np.sum(true_energies[(true_clusters == 0) & (pred_clusters == 0)])\n",
    "    incorrect_noise_as_signal = np.sum(true_energies[(true_clusters == 0) & (pred_clusters != 0)])\n",
    "    correct_signal = np.sum(true_energies[(true_clusters != 0) & (pred_clusters != 0)])\n",
    "    incorrect_signal_as_noise = np.sum(true_energies[(true_clusters != 0) & (pred_clusters == 0)])\n",
    "    \n",
    "    fractions = {\n",
    "        'correct_noise': correct_noise / total_energy if total_energy > 0 else 0,\n",
    "        'incorrect_noise_as_signal': incorrect_noise_as_signal / total_energy if total_energy > 0 else 0,\n",
    "        'incorrect_signal_as_noise': incorrect_signal_as_noise / total_energy if total_energy > 0 else 0,\n",
    "        'correct_signal': correct_signal / total_energy if total_energy > 0 else 0,\n",
    "        'pred_noise': pred_noise_energy / total_energy if total_energy > 0 else 0,\n",
    "        'pred_signal': pred_signal_energy / total_energy if total_energy > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return fractions\n",
    "\n",
    "def generate_table_1(fractions):\n",
    "    data = {\n",
    "        'True / Predicted': ['True Noise', 'True Signal'],\n",
    "        'Predicted Noise': [fractions['correct_noise'], fractions['incorrect_signal_as_noise']],\n",
    "        'Predicted Signal': [fractions['incorrect_noise_as_signal'], fractions['correct_signal']]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('True / Predicted', inplace=True)\n",
    "    print(\"Table 1:\\n\")\n",
    "    print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "    return df\n",
    "\n",
    "def compute_match_statistics(true_energies, true_clusters, pred_clusters):\n",
    "    true_total_energy = np.sum(true_energies[true_clusters != 0])\n",
    "    pred_total_energy = np.sum(true_energies[pred_clusters != 0])\n",
    "    \n",
    "    matched_truth_energy = np.sum(true_energies[(true_clusters != 0) & (pred_clusters != 0)])\n",
    "    unmatched_truth_energy = np.sum(true_energies[(true_clusters != 0) & (pred_clusters == 0)])\n",
    "    matched_pred_energy = np.sum(true_energies[(true_clusters != 0) & (pred_clusters != 0)])\n",
    "    unmatched_pred_energy = np.sum(true_energies[(true_clusters == 0) & (pred_clusters != 0)])\n",
    "    \n",
    "    match_statistics = {\n",
    "        'matched_truth_energy': matched_truth_energy / true_total_energy if true_total_energy > 0 else 0,\n",
    "        'unmatched_truth_energy': unmatched_truth_energy / true_total_energy if true_total_energy > 0 else 0,\n",
    "        'matched_pred_energy': matched_pred_energy / pred_total_energy if pred_total_energy > 0 else 0,\n",
    "        'unmatched_pred_energy': unmatched_pred_energy / pred_total_energy if pred_total_energy > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return match_statistics\n",
    "\n",
    "def generate_table_2(match_statistics):\n",
    "    data = {\n",
    "        'Matched/Unmatched': ['Matched Truth', 'Unmatched Truth', 'Matched Predicted', 'Unmatched Predicted'],\n",
    "        'Energy Fraction': [\n",
    "            match_statistics['matched_truth_energy'], \n",
    "            match_statistics['unmatched_truth_energy'],\n",
    "            match_statistics['matched_pred_energy'], \n",
    "            match_statistics['unmatched_pred_energy']\n",
    "        ]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('Matched/Unmatched', inplace=True)\n",
    "    print(\"Table 2:\\n\")\n",
    "    print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    files = glob.glob(file_pattern)[:file_limit]\n",
    "    all_fractions = []\n",
    "    all_match_statistics = []\n",
    "\n",
    "    for file_path in files:\n",
    "        data, score_noise_filter, pass_noise_filter, out_gravnet = load_data(file_path)\n",
    "        true_energies, true_clusters = process_data(data)\n",
    "        pred_clusters = process_gravnet(score_noise_filter, pass_noise_filter, out_gravnet)\n",
    "        \n",
    "        fractions = compute_statistics(true_energies, true_clusters, pred_clusters)\n",
    "        all_fractions.append(fractions)\n",
    "        \n",
    "        match_statistics = compute_match_statistics(true_energies, true_clusters, pred_clusters)\n",
    "        all_match_statistics.append(match_statistics)\n",
    "    \n",
    "    average_fractions = {key: np.mean([d[key] for d in all_fractions]) for key in all_fractions[0]}\n",
    "    average_match_statistics = {key: np.mean([d[key] for d in all_match_statistics]) for key in all_match_statistics[0]}\n",
    "    \n",
    "    print(f\"Total events: {len(files)}\")\n",
    "    \n",
    "    table_1 = generate_table_1(average_fractions)\n",
    "    table_2 = generate_table_2(average_match_statistics)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
